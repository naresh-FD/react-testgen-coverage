#!/usr/bin/env node

/**
 * generate-pretrained.mjs ‚Äî Use a pre-trained model (no fine-tuning) with
 * smart prompts to generate tests. Works as a "day 0" solution while
 * you prepare training data and fine-tune.
 *
 * Setup:
 *   ollama pull deepseek-coder:1.3b-instruct   (small, fast, ~0.8GB)
 *   ollama pull deepseek-coder:6.7b-instruct    (better quality, ~4GB)
 *   ollama pull codellama:7b-instruct            (alternative, ~4GB)
 *
 * Usage:
 *   node scripts/generate-pretrained.mjs --file src/MyComponent.tsx
 *   node scripts/generate-pretrained.mjs --file src/MyComponent.tsx --model deepseek-coder:6.7b-instruct
 */

import fs from 'fs';
import path from 'path';
import { loadTypeScript } from '../analysis/ts-loader.mjs';
import { ComponentAnalyzer } from '../analysis/component-analyzer.mjs';
import { PromptBuilder } from '../analysis/prompt-builder.mjs';

const args = process.argv.slice(2);
const getArg = (name, def) => {
  const idx = args.indexOf(`--${name}`);
  return idx !== -1 && args[idx + 1] ? args[idx + 1] : def;
};

const OLLAMA_URL = getArg('url', 'http://localhost:11434');
const MODEL = getArg('model', 'deepseek-coder:1.3b-instruct');
const FILE = getArg('file');

async function main() {
  if (!FILE) {
    console.log('Usage: node scripts/generate-pretrained.mjs --file <path.tsx> [--model <name>]');
    console.log('\nAvailable models (install with ollama pull <name>):');
    console.log('  deepseek-coder:1.3b-instruct   ‚Äî Fast, 0.8GB (default)');
    console.log('  deepseek-coder:6.7b-instruct   ‚Äî Better quality, 4GB');
    console.log('  codellama:7b-instruct           ‚Äî Alternative, 4GB');
    process.exit(0);
  }

  await loadTypeScript();

  const filePath = path.resolve(FILE);
  if (!fs.existsSync(filePath)) {
    console.error(`‚ùå File not found: ${filePath}`);
    process.exit(1);
  }

  // Check Ollama
  try {
    const res = await fetch(`${OLLAMA_URL}/api/tags`);
    if (!res.ok) throw new Error();
  } catch {
    console.error('‚ùå Ollama not running. Install from https://ollama.ai then run: ollama serve');
    process.exit(1);
  }

  const sourceCode = fs.readFileSync(filePath, 'utf-8');
  const analyzer = new ComponentAnalyzer(sourceCode, filePath);
  const components = analyzer.analyze();

  if (components.length === 0) {
    console.error('‚ùå No React components found in file');
    process.exit(1);
  }

  const comp = components.find(c => c.isExported || c.isDefault) || components[0];
  console.log(`\nüîç Analyzed: ${comp.name}`);
  console.log(`   Props: ${comp.props.length}, Buttons: ${comp.buttons.length}, Inputs: ${comp.inputs.length}`);
  console.log(`   State: ${comp.state.length}, Handlers: ${comp.handlers.length}`);
  console.log(`   Contexts: ${comp.contexts.join(', ') || 'none'}`);

  const prompt = PromptBuilder.buildInferencePrompt(comp, sourceCode);

  console.log(`\nü§ñ Generating with ${MODEL}... (this may take 30-120 seconds)`);
  const startTime = Date.now();

  const res = await fetch(`${OLLAMA_URL}/api/generate`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: MODEL,
      system: `You are a React testing expert. Generate a complete Jest + React Testing Library test file.
Rules:
- Import renderWithProviders from the test-utils folder (it wraps all providers including MemoryRouter)
- Mock framer-motion and lucide-react icons if the component imports them
- Use screen queries (getByRole, getByText, getByLabelText)
- Use userEvent.setup() then await user.click/type for interactions
- Create realistic mock data matching the component's TypeScript interfaces
- Every it() block must have at least one expect() assertion
- Test rendering, props variations, user interactions, and conditional branches
- Use beforeEach with jest.clearAllMocks() when using jest.fn()
- Output ONLY the test file code, no explanations`,
      prompt: prompt,
      stream: false,
      options: {
        temperature: 0.3,
        top_p: 0.9,
        num_predict: 4096,
        repeat_penalty: 1.1,
      },
    }),
  });

  const data = await res.json();
  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  console.log(`   ‚è±Ô∏è  Done in ${elapsed}s`);

  // Extract code
  let testCode = data.response;
  const codeMatch = testCode.match(/```(?:tsx?|typescript)?\s*\n([\s\S]*?)```/);
  if (codeMatch) testCode = codeMatch[1];
  else if (testCode.indexOf('import') > 0) testCode = testCode.substring(testCode.indexOf('import'));

  // Write file
  const testPath = path.join(
    path.dirname(filePath), '__tests__',
    path.basename(filePath, '.tsx') + '.test.tsx'
  );
  fs.mkdirSync(path.dirname(testPath), { recursive: true });

  const header = `/**
 * @generated by react-testgen-llm (pretrained: ${MODEL})
 * Generated: ${new Date().toISOString().split('T')[0]}
 * Source: ${path.basename(filePath)}
 * NOTE: Review and fix before committing ‚Äî pretrained models are less accurate than fine-tuned ones.
 */\n`;

  fs.writeFileSync(testPath, header + testCode.trim() + '\n', 'utf-8');
  console.log(`\n‚úÖ Generated: ${path.relative(process.cwd(), testPath)}`);
  console.log(`\nüí° Tip: Run 'npx jest ${path.relative(process.cwd(), testPath)}' to test it`);
  console.log(`   If it has issues, fix them and save the pair as training data for fine-tuning!`);
}

main().catch(err => {
  console.error('‚ùå', err.message);
  process.exit(1);
});
